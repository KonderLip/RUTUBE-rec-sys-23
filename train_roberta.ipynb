{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecb2b58",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db76f968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n",
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n",
      "4.30.2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import torch.nn as nn\n",
    "#from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import transformers\n",
    "from transformers import RobertaConfig, RobertaModel, get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from typing import Sequence\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bacb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 56\n",
    "workers = True\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "os.environ[\"PL_SEED_WORKERS\"] = f\"{int(workers)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03d53f",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9191d074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179428\n"
     ]
    }
   ],
   "source": [
    "dict_item_to_author = pd.read_csv('./data/item_authors.csv')\n",
    "print(dict_item_to_author['author_title'].nunique())\n",
    "dict_item_to_author = dict(zip(dict_item_to_author['item_id'], dict_item_to_author['author_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3b1142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179427"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(list(dict_item_to_author.values())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44935aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed627ae07b2a4c8ca619832f344dfae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1393055 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_history = []\n",
    "train_items = set()\n",
    "\n",
    "with open('./data/train') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        videos = line.strip().split(' ')\n",
    "        videos = list(map(int, videos))\n",
    "        start_history.append(videos)\n",
    "        train_items.update(videos)\n",
    "start_history_lengths = np.asarray([len(x) for x in start_history])\n",
    "bin_thresholds = np.quantile(start_history_lengths, q=[np.arange(0.1, 1.0, 0.1)])\n",
    "start_history_bins = np.digitize(start_history_lengths, bins=bin_thresholds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d31e496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27757278"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(start_history_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b1817f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  8.,  9., 10., 12., 14., 17., 23., 38.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f384ffe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(start_history_lengths, bins=64)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6a30ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(start_history_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e7ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 8, ..., 1, 4, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_history_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f5b0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_history, val_start_history = train_test_split(start_history, test_size=0.2, random_state=56, stratify=start_history_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3949b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114444, 278611)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_start_history), len(val_start_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d24a82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_history_lengths = np.asarray([len(x) for x in train_start_history])\n",
    "train_bin_thresholds = np.quantile(train_start_history_lengths, q=[np.arange(0.1, 1.0, 0.1)])\n",
    "train_start_history_bins = np.digitize(train_start_history_lengths, bins=train_bin_thresholds.flatten())\n",
    "\n",
    "val_start_history_lengths = np.asarray([len(x) for x in val_start_history])\n",
    "val_bin_thresholds = np.quantile(val_start_history_lengths, q=[np.arange(0.1, 1.0, 0.1)])\n",
    "val_start_history_bins = np.digitize(val_start_history_lengths, bins=val_bin_thresholds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4128840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(train_start_history_lengths, bins=64)\n",
    "sns.histplot(val_start_history_lengths, bins=64)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11dcdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemEncoder:\n",
    "    def __init__(self, keep_top_n):\n",
    "        self.keep_top_n = keep_top_n\n",
    "        self.item_to_id = None\n",
    "        self.id_to_item = None\n",
    "        self.counter = Counter()\n",
    "        self.is_locked = False\n",
    "        \n",
    "    def fit(self, data):\n",
    "        if self.is_locked:\n",
    "            raise Exception(\"encoder has been locked\")\n",
    "        self.counter.update(data)\n",
    "        \n",
    "    def transform(self, data):\n",
    "        if not self.is_locked:\n",
    "            raise Exception(\"transforming with unlocked encoder is not allowed\")\n",
    "        return np.vectorize(lambda x: self.item_to_id.get(x, 0))(data) # unk key is 0\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        if not self.is_locked:\n",
    "            raise Exception(\"transforming with unlocked encoder is not allowed\")\n",
    "        return np.vectorize(self.id_to_item.__getitem__)(data)\n",
    "    \n",
    "    def lock(self):\n",
    "        self.id_to_item = [-1] + list(map(lambda x: x[0], self.counter.most_common(self.keep_top_n)))\n",
    "        self.item_to_id = {x: i for i, x in enumerate(self.id_to_item)}\n",
    "        assert len(self.id_to_item) == len(self.item_to_id)\n",
    "        self.is_locked = True\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.id_to_item)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bcd948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_encoder = ItemEncoder(keep_top_n=None)\n",
    "for seq in train_start_history:\n",
    "    item_encoder.fit(seq)\n",
    "item_encoder.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc9d1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_encoder = ItemEncoder(keep_top_n=None)\n",
    "for seq in train_start_history:\n",
    "    author_encoder.fit(map(lambda x: dict_item_to_author[x], seq))\n",
    "author_encoder.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20296a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1021298, 1167029)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_encoder), len(train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7eb2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_start_history = [seq for seq in val_start_history if set(seq).issubset(train_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee2f2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(144691, 327703),\n",
       " (302657, 313071),\n",
       " (1594159, 295979),\n",
       " (1761620, 263484),\n",
       " (68646, 237070),\n",
       " (170129, 227356),\n",
       " (836422, 201378),\n",
       " (1508623, 179780),\n",
       " (803844, 146045),\n",
       " (902590, 143146)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_encoder.counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219a44c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49fd96c22334b20901aff53d0718683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_true = []\n",
    "most_common_item = item_encoder.counter.most_common(1)[0][0]\n",
    "for i, _ in tqdm(enumerate(val_start_history)):\n",
    "    answer = val_start_history[i][-1]\n",
    "    val_true += [answer]\n",
    "    val_start_history[i][-1] = most_common_item # magic number for sanity check "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3677e8",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "683f4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialTokens:\n",
    "    def __init__(self, tokens):\n",
    "        assert len(tokens) == len(set(tokens))\n",
    "        assert 'pad_token' in tokens\n",
    "        assert 'mask_token' in tokens\n",
    "        self.n_tokens = len(tokens)\n",
    "        for i, x in enumerate(tokens):\n",
    "            setattr(self, x, i)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baf1c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2d_to_np(list2d, pad_token=-1):\n",
    "    np_list2d = np.ones(\n",
    "        [len(list2d), len(max(list2d, key=lambda x: len(x)))], dtype=int\n",
    "    ) * pad_token\n",
    "    for i, j in enumerate(list2d):\n",
    "        np_list2d[i][0:len(j)] = j\n",
    "    return np_list2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39f96643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YaCupDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        item_encoder,\n",
    "        author_encoder,\n",
    "        item_to_author_dict,\n",
    "        special_tokens: Sequence[str],\n",
    "        mask_prob: float,\n",
    "        force_last_token_mask_prob: float,\n",
    "        max_len: int\n",
    "    ):\n",
    "        self.special_tokens = SpecialTokens(special_tokens)\n",
    "        self.vocab_size = len(item_encoder) + len(self.special_tokens)\n",
    "        self.author_size = len(author_encoder) + 1 # 0 is masked author\n",
    "        self.mask_prob = mask_prob\n",
    "        self.force_last_token_mask_prob = force_last_token_mask_prob\n",
    "        self.max_len = max_len\n",
    "        self.item_encoder = item_encoder\n",
    "        self.author_encoder = author_encoder\n",
    "        self.item_to_author_dict = item_to_author_dict\n",
    "        self.data, self.data_lengths, self.data_authors = YaCupDataset._preprocess_list_2d(\n",
    "            data,\n",
    "            token_shift=len(self.special_tokens),\n",
    "            pad_token=self.special_tokens.pad_token,\n",
    "            item_encoder=self.item_encoder,\n",
    "            author_encoder=self.author_encoder,\n",
    "            item_to_author_dict = self.item_to_author_dict,\n",
    "            author_shift = 1, # masked tokens are special \n",
    "        )\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self._preprocess_sequence(self.data[index], self.data_lengths[index], self.data_authors[index])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _preprocess_list_2d(list2d, token_shift, pad_token, item_encoder, author_encoder, item_to_author_dict, author_shift):\n",
    "        np_list2d = np.ones(\n",
    "            [len(list2d), len(max(list2d, key=lambda x: len(x)))], dtype=int\n",
    "        ) * pad_token\n",
    "        np_lengths = np.zeros(len(list2d), dtype=int)\n",
    "        np_list2d_authors = np.zeros(\n",
    "            [len(list2d), len(max(list2d, key=lambda x: len(x)))], dtype=int\n",
    "        )\n",
    "        for i, j in enumerate(list2d):\n",
    "            np_list2d[i][0:len(j)] = item_encoder.transform(j)[::-1]  # reverse for better pos encoding learning\n",
    "            np_list2d[i][0:len(j)] += token_shift\n",
    "            np_lengths[i] = len(j)\n",
    "            # transform items to authors, encode authors with author_encoder, reverse the order just start above\n",
    "            np_list2d_authors[i][0:len(j)] = author_encoder.transform(\n",
    "                list(map(lambda x: item_to_author_dict[x], j))\n",
    "            )[::-1]\n",
    "            np_list2d_authors[i][0:len(j)] += author_shift\n",
    "        return np_list2d, np_lengths, np_list2d_authors\n",
    "    \n",
    "    def _preprocess_sequence(self, sequence_ids, length, author_ids):\n",
    "        input_ids = torch.LongTensor(sequence_ids).clone()\n",
    "        labels = torch.LongTensor(sequence_ids).clone()\n",
    "            \n",
    "        if np.random.random() < self.force_last_token_mask_prob:\n",
    "            mask = torch.zeros(sequence_ids.shape)\n",
    "            mask[0] = True\n",
    "        else:\n",
    "            mask = torch.rand(sequence_ids.shape)\n",
    "            mask = (mask < self.mask_prob)\n",
    "        mask *= (input_ids > len(self.special_tokens)) # don't mask special tokens\n",
    "        if mask.sum() == 0:\n",
    "            mask = torch.zeros(sequence_ids.shape)\n",
    "            mask[0] = True\n",
    "            mask *= (input_ids > len(self.special_tokens)) # don't mask special tokens\n",
    "        mask_indices = mask.nonzero().flatten()\n",
    "        n_masked = torch.LongTensor([len(mask_indices)])\n",
    "        input_ids[mask_indices] = self.special_tokens.mask_token\n",
    "        attention_mask = (input_ids != self.special_tokens.pad_token) * 1.0\n",
    "        token_type_ids = torch.LongTensor(author_ids).clone()\n",
    "        token_type_ids[mask_indices] = 0 # masked segment\n",
    "        author_labels = torch.LongTensor(author_ids).clone()\n",
    "        \n",
    "        author_labels[token_type_ids != 0] = -100 # calculate loss only for masked tokens\n",
    "        author_labels[length:] = -100 # remove pad tokens from loss\n",
    "        labels[input_ids != self.special_tokens.mask_token] = -100 # calculate loss only for masked tokens\n",
    "        # labels[input_ids == self.special_tokens.pad_token] = -100 # calculate loss only for non-pad tokens\n",
    "        inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "            'author_labels': author_labels,\n",
    "            'n_masked': n_masked,\n",
    "            'last_token_index': torch.LongTensor([length - 1]),\n",
    "        }\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5e8a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YaCupDataset(\n",
    "    train_start_history,\n",
    "    item_encoder=item_encoder,\n",
    "    author_encoder=author_encoder,\n",
    "    item_to_author_dict=dict_item_to_author,\n",
    "    special_tokens=['cls_token', 'sep_token', 'mask_token', 'pad_token'],\n",
    "    mask_prob=0.2,\n",
    "    force_last_token_mask_prob=0.0,\n",
    "    max_len=256,\n",
    ")\n",
    "\n",
    "val_dataset = YaCupDataset(\n",
    "    val_start_history,\n",
    "    item_encoder=item_encoder,\n",
    "    author_encoder=author_encoder,\n",
    "    item_to_author_dict=dict_item_to_author,\n",
    "    special_tokens=['cls_token', 'sep_token', 'mask_token', 'pad_token'],\n",
    "    mask_prob=0.2,\n",
    "    force_last_token_mask_prob=1.0,\n",
    "    max_len=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17dd7b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=24,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=24,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee236c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "class YacupModel(nn.Module):\n",
    "    def __init__(self, config, label_smoothing):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.bert = RobertaModel(config)\n",
    "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))\n",
    "        \n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.bert.init_weights()\n",
    "                \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        filter_history_items: Optional[bool] = False,\n",
    "        loss_class_weight: Optional[torch.Tensor] = None,\n",
    "        trim_length: Optional[int] = None,\n",
    "        item_to_author_mapper: Optional[torch.Tensor] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], MaskedLMOutput]:\n",
    "        \"\"\"Mostly from https://github.com/huggingface/transformers/blob/v4.23.1/src/transformers/models/bert/modeling_bert.py#L1288\"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        trim_length = trim_length if trim_length is not None else self.config.max_position_embeddings\n",
    "        \n",
    "        if item_to_author_mapper is None:\n",
    "            raise Exception(\"item_to_author_mapper must be passed\")\n",
    "        \n",
    "        outputs = self.bert(\n",
    "            input_ids[:, :trim_length],\n",
    "            attention_mask=attention_mask[:, :trim_length],\n",
    "            token_type_ids=token_type_ids[:, :trim_length],\n",
    "            position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        # sum of item and author embeddings\n",
    "        output_embedding_matrix = self.bert.embeddings.word_embeddings.weight + self.bert.embeddings.token_type_embeddings.weight[item_to_author_mapper] # torch.index_select(self.bert.embeddings.token_type_embeddings.weight, dim=0, index=item_to_author_mapper)\n",
    "        prediction_scores = (sequence_output @ output_embedding_matrix.T) + self.bias\n",
    "        if filter_history_items:\n",
    "            prediction_scores.scatter_(dim=2, index=input_ids.unsqueeze(1), src=-10000 * torch.ones_like(input_ids.unsqueeze(1),dtype=prediction_scores.dtype))\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            # for some reason CrossEntropyLoss raises out of bounds exception when executed with `reduction = 'mean'` (default) when `label_smoothing != 0` and `weight is not None`\n",
    "            # hence, to dodge this issue we init CrossEntropyLoss with `reduction='none'` and later we average the numbers\n",
    "            if self.label_smoothing != 0.0:\n",
    "                loss_fct = CrossEntropyLoss(weight=loss_class_weight, label_smoothing=self.label_smoothing, reduction='none')\n",
    "                masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels[:, :trim_length].flatten()).mean()\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss(weight=loss_class_weight, label_smoothing=self.label_smoothing)\n",
    "                masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels[:, :trim_length].flatten())\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores,) + outputs[2:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return MaskedLMOutput(\n",
    "            loss=masked_lm_loss,\n",
    "            logits=prediction_scores,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e17bb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = RobertaConfig(\n",
    "    vocab_size=dataset.vocab_size,\n",
    "    hidden_size=512,\n",
    "    max_position_embeddings=256,\n",
    "    attention_probs_dropout_prob=0.0,\n",
    "    hidden_act='gelu',\n",
    "    hidden_dropout_prob=0.0,\n",
    "    initializer_range=0.02,\n",
    "    intermediate_size=1024,\n",
    "    num_attention_heads=4,\n",
    "    num_hidden_layers=2,\n",
    "    type_vocab_size=dataset.author_size,\n",
    ")\n",
    "\n",
    "model = YacupModel(\n",
    "    model_config,\n",
    "    label_smoothing=0.0\n",
    ")\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "856fb7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "YacupModel                                                   1,021,302\n",
       "RobertaModel: 1-1                                          --\n",
       "    RobertaEmbeddings: 2-1                                --\n",
       "        Embedding: 3-1                                   522,906,624\n",
       "        Embedding: 3-2                                   131,072\n",
       "        Embedding: 3-3                                   45,438,976\n",
       "        LayerNorm: 3-4                                   1,024\n",
       "        Dropout: 3-5                                     --\n",
       "    RobertaEncoder: 2-2                                   --\n",
       "        ModuleList: 3-6                                  4,205,568\n",
       "    RobertaPooler: 2-3                                    --\n",
       "        Linear: 3-7                                      262,656\n",
       "        Tanh: 3-8                                        --\n",
       "=====================================================================================\n",
       "Total params: 573,967,222\n",
       "Trainable params: 573,967,222\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5696ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mrr(predict, answer):\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == answer:\n",
    "            return 1. / (i + 1)\n",
    "    return 0\n",
    "\n",
    "max_prediction_len = 10\n",
    "\n",
    "def calc_score(y_true, y_pred):\n",
    "    mrr_score = 0\n",
    "    for (pred, answer) in tqdm(zip(y_pred, y_true)):\n",
    "        if len(pred) > max_prediction_len:\n",
    "            raise ValueError('$maximum prediction length is {}, got {}$'.format(max_prediction_len, len(y_pred[i])))\n",
    "        mrr_score += calc_mrr(pred, answer)\n",
    "\n",
    "    print(\"MRR@10 = {}\".format(mrr_score / len(y_true)))\n",
    "    return mrr_score / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3d3891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crutch: put loops in scope to avoid memory fragmentaion\n",
    "\n",
    "def train(model, dl, DEVICE, TRIM_LENGTH):\n",
    "    item_to_author_indices_nn = torch.LongTensor(list(dict_item_to_author_nn.get(item_id, 1) for item_id in range(dataset.vocab_size))).to(DEVICE, non_blocking=True)\n",
    "    loss_class_weight = torch.ones(dataset.vocab_size)\n",
    "    loss_class_weight[:len(dataset.special_tokens) + 1] = 0.0 # we don't care about a special token loss or an unk token loss\n",
    "    loss_class_weight = loss_class_weight.to(DEVICE, non_blocking=True)\n",
    "\n",
    "    tbar = tqdm(dl, file=sys.stdout)\n",
    "    loss_sum = 0.0\n",
    "    n_masked_sum = 0\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(tbar):\n",
    "        with torch.cuda.amp.autocast():\n",
    "            res = model.forward(\n",
    "                input_ids=batch['input_ids'].to(DEVICE, non_blocking=True),\n",
    "                attention_mask=batch['attention_mask'].to(DEVICE, non_blocking=True),\n",
    "                token_type_ids=batch['token_type_ids'].to(DEVICE, non_blocking=True),\n",
    "                labels=batch['labels'].to(DEVICE, non_blocking=True),\n",
    "                filter_history_items=True,\n",
    "                loss_class_weight=loss_class_weight,\n",
    "                trim_length=TRIM_LENGTH,\n",
    "                item_to_author_mapper=item_to_author_indices_nn\n",
    "            )\n",
    "            batch_masked_sum = batch['n_masked'].to(DEVICE, non_blocking=True).sum()\n",
    "            loss = res.loss # / batch_masked_sum; normalization hurts performance\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (idx + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "        loss_sum += res.loss.detach().item()\n",
    "        n_masked_sum += batch_masked_sum.detach().item()\n",
    "        tbar.set_postfix_str(f\"Epoch {e + 1} Loss: {loss_sum / n_masked_sum} lr: {optimizer.param_groups[0]['lr']:.5}\")\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            wandb.log({\"loss\": loss_sum / n_masked_sum})\n",
    "\n",
    "def validate(model, dl, DEVICE, TRIM_LENGTH):\n",
    "    item_to_author_indices_nn = torch.LongTensor(list(dict_item_to_author_nn.get(item_id, 1) for item_id in range(dataset.vocab_size))).to(DEVICE, non_blocking=True)\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    for batch in tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                batch_input_ids = batch['input_ids'].to(DEVICE, non_blocking=True)\n",
    "                res = model.forward(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch['attention_mask'].to(DEVICE, non_blocking=True),\n",
    "                    token_type_ids=batch['token_type_ids'].to(DEVICE, non_blocking=True),\n",
    "                    labels=batch['labels'].to(DEVICE, non_blocking=True),\n",
    "                    filter_history_items=True,\n",
    "                    trim_length=TRIM_LENGTH,\n",
    "                    item_to_author_mapper=item_to_author_indices_nn\n",
    "                )\n",
    "\n",
    "                scores = res.logits[:, 0, :].unsqueeze(1) # predict last item\n",
    "                scores[:, :, :len(dataset.special_tokens) + 1] = -10000 # +1 due to unk token\n",
    "                # remove historical items form predictions; allow only new items\n",
    "                # scores.scatter_(dim=2, index=batch_input_ids.unsqueeze(1), src=-10000 * torch.ones_start(batch_input_ids.unsqueeze(1),dtype=scores.dtype))\n",
    "                scores = scores.squeeze(1)\n",
    "                preds = torch.topk(scores, k=10, dim=1).indices - len(dataset.special_tokens)\n",
    "                all_preds += preds.detach().cpu().numpy().tolist()\n",
    "\n",
    "    all_preds = item_encoder.inverse_transform(all_preds)\n",
    "    return all_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c9c6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_checkpoint(checkpoint_name, model, optimizer, new_lr=None):\n",
    "    checkpoint = torch.load(checkpoint_name)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    if new_lr is not None:\n",
    "        for param_groups in checkpoint['optimizer']['param_groups']:\n",
    "            param_groups['lr'] = new_lr\n",
    "            param_groups['initial_lr'] = new_lr\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127764ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db9796eefb5412782e585dca87581df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2320659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "model.to(DEVICE)\n",
    "TRIM_LENGTH = 64\n",
    "best_val_score = -10000.0\n",
    "\n",
    "checkpoint_name = None\n",
    "\n",
    "# +1 is a shift for masked_author token\n",
    "dict_item_to_author_nn = {item_encoder.transform(k).tolist() + len(dataset.special_tokens) :author_encoder.transform(v).tolist() + 1 for k, v in tqdm(dict_item_to_author.items())}\n",
    "# 1 is an unknown author token\n",
    "# item_to_author_indices_nn = torch.LongTensor(list(dict_item_to_author_nn.get(item_id, 1) for item_id in range(dataset.vocab_size))).to(DEVICE)\n",
    "\n",
    "epochs=20\n",
    "accumulation_steps=100\n",
    "learning_rate = 2.5e-4\n",
    "num_train_optimization_steps = int(epochs * len(dataloader) / accumulation_steps)\n",
    "correct_bias = True\n",
    "weight_decay = 1e-05\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "param_optimizer = list(model.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters, lr=learning_rate, correct_bias=correct_bias, \n",
    ")\n",
    "\n",
    "if checkpoint_name is not None:\n",
    "    load_from_checkpoint(checkpoint_name, model, optimizer, new_lr=learning_rate)\n",
    "\n",
    "warmup_steps = int(1 * len(dataloader) / accumulation_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=num_train_optimization_steps\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "run = wandb.init(project='Rutube', config=model_config.to_diff_dict())\n",
    "run.config.update({\n",
    "    'n_whitelisted_items': item_encoder.keep_top_n,\n",
    "    'mask_prob': dataset.mask_prob,\n",
    "    'force_last_token_mask_prob': dataset.force_last_token_mask_prob,\n",
    "    'batch_size': dataloader.batch_size,\n",
    "    'epochs': epochs,\n",
    "    'accumulation_steps': accumulation_steps,\n",
    "    'learning_rate': learning_rate,\n",
    "    'warmup_steps': warmup_steps,\n",
    "    'num_train_optimization_steps': num_train_optimization_steps,\n",
    "    'correct_bias': correct_bias,\n",
    "    'label_smoothing': model.label_smoothing,\n",
    "    'weight_decay': weight_decay,\n",
    "    'from_checkpoint': checkpoint_name,\n",
    "})\n",
    "\n",
    "for e in range(epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    train(\n",
    "        model,\n",
    "        dataloader,\n",
    "        DEVICE=DEVICE,\n",
    "        TRIM_LENGTH=TRIM_LENGTH\n",
    "    )\n",
    "            \n",
    "    all_preds = validate(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        DEVICE=DEVICE,\n",
    "        TRIM_LENGTH=TRIM_LENGTH\n",
    "    )\n",
    "    \n",
    "    checkpoint = { \n",
    "        'epoch': e,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, f'output/checkpoint_{run.id}_{e}.pth')\n",
    "\n",
    "    score = calc_score(val_true[:len(all_preds)], all_preds)\n",
    "    if score > best_val_score:\n",
    "        best_val_score = score\n",
    "        torch.save(model.state_dict(), f'output/model_{run.id}.pt')\n",
    "    wandb.log({\"score\": score})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb55a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
